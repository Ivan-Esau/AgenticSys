{
  "provider": "groq",
  "display_name": "Groq",
  "description": "Ultra-fast inference with open-source models",
  "api_key_env": "GROQ_API_KEY",
  "base_url_env": null,
  "default_base_url": null,
  "langchain_class": "langchain_groq.ChatGroq",
  "package_name": "langchain-groq",
  "models": {
    "llama-3.1-70b": {
      "id": "llama-3.1-70b-versatile",
      "display_name": "Llama 3.1 70B",
      "description": "Large parameter model for complex tasks",
      "context_length": 128000,
      "cost_per_1k_tokens": 0.00059,
      "capabilities": ["chat", "coding", "reasoning"],
      "recommended_for": ["coding", "complex-reasoning"]
    },
    "llama-3.1-8b": {
      "id": "llama-3.1-8b-instant",
      "display_name": "Llama 3.1 8B",
      "description": "Fast and efficient model for most tasks",
      "context_length": 128000,
      "cost_per_1k_tokens": 0.000055,
      "capabilities": ["chat", "basic-coding", "reasoning"],
      "recommended_for": ["general", "planning", "review"]
    },
    "mixtral-8x7b": {
      "id": "mixtral-8x7b-32768",
      "display_name": "Mixtral 8x7B",
      "description": "Mixture of experts model for diverse tasks",
      "context_length": 32768,
      "cost_per_1k_tokens": 0.00024,
      "capabilities": ["chat", "coding", "multilingual"],
      "recommended_for": ["multilingual", "diverse-tasks"]
    }
  },
  "default_model": "llama-3.1-8b",
  "task_preferences": {
    "coding": "llama-3.1-70b",
    "testing": "llama-3.1-70b",
    "planning": "llama-3.1-8b",
    "review": "llama-3.1-8b",
    "debugging": "llama-3.1-70b",
    "analysis": "mixtral-8x7b"
  },
  "initialization_params": {
    "temperature": 0,
    "max_retries": 5
  }
}